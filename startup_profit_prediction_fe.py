# -*- coding: utf-8 -*-
"""Startup Profit Prediction FE.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FPSizqPJs62IYUnu_Atn12jKgMkCROC1
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

#from google.colab import files
import io

#uploaded = files.upload()

df = pd.read_csv('50_Startups.csv')

df.head()

df.info()

df.describe()

state_dummies = pd.get_dummies(df['State'], prefix = 'state', drop_first = True)
df = pd.concat([df, state_dummies], axis = 1)

df.head()

df.drop(['State'], axis = 1, inplace = True)

df.head()

X = df.drop(['Profit'], axis = 1)
Y = df['Profit']
from sklearn.model_selection import train_test_split
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 0)

X_train.head()

from sklearn.linear_model import LinearRegression
from sklearn.linear_model import Lasso
from sklearn.tree import DecisionTreeRegressor
from sklearn.model_selection import ShuffleSplit
from sklearn.model_selection import GridSearchCV

def find_best_model_using_gridsearchcv(X, Y):
  algos = {
      'linear_regression': {
          'model': LinearRegression(),
          'params': {
              'fit_intercept': [True, False],
              'normalize': [True, False],
              'copy_X': [True, False]
          }
      },
      'lasso': {
          'model': Lasso(),
          'params': {
              'alpha': [1, 2],
              'selection': ['random', 'cyclic']
          }
      },
      'decision_tree': {
          'model': DecisionTreeRegressor(),
          'params':{
              'criterion': ['mse', 'friedman_mse'],
              'splitter': ['best', 'random']
          }
      }
  }
  scores = []
  cv = ShuffleSplit(n_splits = 5, test_size = 0.2, random_state = 0)
  for algo_name, config in algos.items():
    gs = GridSearchCV(config['model'], config['params'], cv = cv, return_train_score = False)
    gs.fit(X, Y)
    scores.append({
        'model': algo_name,
        'best_score': gs.best_score_,
        'best_params': gs.best_params_
    })
  return pd.DataFrame(scores, columns = ['model', 'best_score', 'best_params'])

pd.set_option('display.max_colwidth', 100)
find_best_model_using_gridsearchcv(X, Y)

model_lr = LinearRegression(copy_X = True, fit_intercept = True, normalize = True)

model_lr.fit(X_train, Y_train)

model_lr.score(X_test, Y_test)

Y_pred = model_lr.predict(X_test)

Y_pred

model_lr.predict()

def predict_profit(r_d_expenses, administration, marketing, state):
  state_index = np.where(X.columns == 'state_'+str(state))[0][0]
  x = np.zeros(len(X.columns))
  x[0] = r_d_expenses
  x[1] = administration
  x[2] = marketing
  if state_index >= 0:
    x[state_index] = 1
  
  return model_lr.predict([x])[0]

predict_profit(60154, 125652, 458765, 'New York')

import pickle
pickle.dump(model_lr, open('profit_prediction_model.pkl', 'wb'))

# from google.colab import files
# files.download('profit_prediction_model.pkl')

import json

columns = {'data_columns': [col.lower() for col in X.columns]}

with open('columns.json', 'w') as f:
  f.write(json.dumps(columns))

X.head()

# from google.colab import files
# files.download('columns.json')